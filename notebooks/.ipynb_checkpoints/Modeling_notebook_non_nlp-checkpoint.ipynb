{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import punkt\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import recall_score, accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import string\n",
    "from nltk.probability import FreqDist\n",
    "import seaborn as sns\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 30\n",
    "import lexnlp as lnlp\n",
    "import src\n",
    "import importlib\n",
    "import unidecode as unidecode\n",
    "importlib.reload(src)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing SCDB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseId</th>\n",
       "      <th>docketId</th>\n",
       "      <th>caseIssuesId</th>\n",
       "      <th>voteId</th>\n",
       "      <th>dateDecision</th>\n",
       "      <th>decisionType</th>\n",
       "      <th>usCite</th>\n",
       "      <th>sctCite</th>\n",
       "      <th>ledCite</th>\n",
       "      <th>lexisCite</th>\n",
       "      <th>term</th>\n",
       "      <th>naturalCourt</th>\n",
       "      <th>chief</th>\n",
       "      <th>docket</th>\n",
       "      <th>caseName</th>\n",
       "      <th>...</th>\n",
       "      <th>voteUnclear</th>\n",
       "      <th>issue</th>\n",
       "      <th>issueArea</th>\n",
       "      <th>decisionDirection</th>\n",
       "      <th>decisionDirectionDissent</th>\n",
       "      <th>authorityDecision1</th>\n",
       "      <th>authorityDecision2</th>\n",
       "      <th>lawType</th>\n",
       "      <th>lawSupp</th>\n",
       "      <th>lawMinor</th>\n",
       "      <th>majOpinWriter</th>\n",
       "      <th>majOpinAssigner</th>\n",
       "      <th>splitVote</th>\n",
       "      <th>majVotes</th>\n",
       "      <th>minVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946-001</td>\n",
       "      <td>1946-001-01</td>\n",
       "      <td>1946-001-01-01</td>\n",
       "      <td>1946-001-01-01-01</td>\n",
       "      <td>11/18/1946</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 1</td>\n",
       "      <td>67 S. Ct. 6</td>\n",
       "      <td>91 L. Ed. 3</td>\n",
       "      <td>1946 U.S. LEXIS 1724</td>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>Vinson</td>\n",
       "      <td>24</td>\n",
       "      <td>HALLIBURTON OIL WELL CEMENTING CO. v. WALKER e...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80180.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>35 U.S.C. ยง 33</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946-002</td>\n",
       "      <td>1946-002-01</td>\n",
       "      <td>1946-002-01-01</td>\n",
       "      <td>1946-002-01-01-01</td>\n",
       "      <td>11/18/1946</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 14</td>\n",
       "      <td>67 S. Ct. 13</td>\n",
       "      <td>91 L. Ed. 12</td>\n",
       "      <td>1946 U.S. LEXIS 1725</td>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>Vinson</td>\n",
       "      <td>12</td>\n",
       "      <td>CLEVELAND v. UNITED STATES</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>18 U.S.C. ยง 398</td>\n",
       "      <td>81.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946-003</td>\n",
       "      <td>1946-003-01</td>\n",
       "      <td>1946-003-01-01</td>\n",
       "      <td>1946-003-01-01-01</td>\n",
       "      <td>11/18/1946</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 29</td>\n",
       "      <td>67 S. Ct. 1</td>\n",
       "      <td>91 L. Ed. 22</td>\n",
       "      <td>1946 U.S. LEXIS 3037</td>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>Vinson</td>\n",
       "      <td>21</td>\n",
       "      <td>CHAMPLIN REFINING CO. v. UNITED STATES ET AL.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80250.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946-004</td>\n",
       "      <td>1946-004-01</td>\n",
       "      <td>1946-004-01-01</td>\n",
       "      <td>1946-004-01-01-01</td>\n",
       "      <td>11/25/1946</td>\n",
       "      <td>7</td>\n",
       "      <td>329 U.S. 40</td>\n",
       "      <td>67 S. Ct. 167</td>\n",
       "      <td>91 L. Ed. 29</td>\n",
       "      <td>1946 U.S. LEXIS 1696</td>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>Vinson</td>\n",
       "      <td>26</td>\n",
       "      <td>UNITED STATES v. ALCEA BAND OF TILLAMOOKS ET AL.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>49 Stat. 801</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1946-005</td>\n",
       "      <td>1946-005-01</td>\n",
       "      <td>1946-005-01-01</td>\n",
       "      <td>1946-005-01-01-01</td>\n",
       "      <td>11/25/1946</td>\n",
       "      <td>1</td>\n",
       "      <td>329 U.S. 64</td>\n",
       "      <td>67 S. Ct. 154</td>\n",
       "      <td>91 L. Ed. 44</td>\n",
       "      <td>1946 U.S. LEXIS 2997</td>\n",
       "      <td>1946</td>\n",
       "      <td>1301</td>\n",
       "      <td>Vinson</td>\n",
       "      <td>50</td>\n",
       "      <td>UNITED STATES v. HOWARD P. FOLEY CO., INC.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80060.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows ร 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     caseId     docketId    caseIssuesId             voteId dateDecision  \\\n",
       "0  1946-001  1946-001-01  1946-001-01-01  1946-001-01-01-01   11/18/1946   \n",
       "1  1946-002  1946-002-01  1946-002-01-01  1946-002-01-01-01   11/18/1946   \n",
       "2  1946-003  1946-003-01  1946-003-01-01  1946-003-01-01-01   11/18/1946   \n",
       "3  1946-004  1946-004-01  1946-004-01-01  1946-004-01-01-01   11/25/1946   \n",
       "4  1946-005  1946-005-01  1946-005-01-01  1946-005-01-01-01   11/25/1946   \n",
       "\n",
       "   decisionType       usCite        sctCite       ledCite  \\\n",
       "0             1   329 U.S. 1    67 S. Ct. 6   91 L. Ed. 3   \n",
       "1             1  329 U.S. 14   67 S. Ct. 13  91 L. Ed. 12   \n",
       "2             1  329 U.S. 29    67 S. Ct. 1  91 L. Ed. 22   \n",
       "3             7  329 U.S. 40  67 S. Ct. 167  91 L. Ed. 29   \n",
       "4             1  329 U.S. 64  67 S. Ct. 154  91 L. Ed. 44   \n",
       "\n",
       "              lexisCite  term  naturalCourt   chief docket  \\\n",
       "0  1946 U.S. LEXIS 1724  1946          1301  Vinson     24   \n",
       "1  1946 U.S. LEXIS 1725  1946          1301  Vinson     12   \n",
       "2  1946 U.S. LEXIS 3037  1946          1301  Vinson     21   \n",
       "3  1946 U.S. LEXIS 1696  1946          1301  Vinson     26   \n",
       "4  1946 U.S. LEXIS 2997  1946          1301  Vinson     50   \n",
       "\n",
       "                                            caseName  ... voteUnclear  \\\n",
       "0  HALLIBURTON OIL WELL CEMENTING CO. v. WALKER e...  ...         0.0   \n",
       "1                         CLEVELAND v. UNITED STATES  ...         0.0   \n",
       "2      CHAMPLIN REFINING CO. v. UNITED STATES ET AL.  ...         0.0   \n",
       "3   UNITED STATES v. ALCEA BAND OF TILLAMOOKS ET AL.  ...         0.0   \n",
       "4         UNITED STATES v. HOWARD P. FOLEY CO., INC.  ...         0.0   \n",
       "\n",
       "     issue  issueArea  decisionDirection  decisionDirectionDissent  \\\n",
       "0  80180.0        8.0                2.0                       0.0   \n",
       "1  10500.0        1.0                1.0                       0.0   \n",
       "2  80250.0        8.0                2.0                       0.0   \n",
       "3  20150.0        2.0                2.0                       0.0   \n",
       "4  80060.0        8.0                2.0                       0.0   \n",
       "\n",
       "   authorityDecision1  authorityDecision2  lawType  lawSupp         lawMinor  \\\n",
       "0                 4.0                 NaN      6.0    600.0   35 U.S.C. ยง 33   \n",
       "1                 4.0                 NaN      6.0    600.0  18 U.S.C. ยง 398   \n",
       "2                 1.0                 NaN      2.0    207.0              NaN   \n",
       "3                 4.0                 NaN      6.0    600.0     49 Stat. 801   \n",
       "4                 7.0                 NaN      NaN      NaN              NaN   \n",
       "\n",
       "   majOpinWriter  majOpinAssigner  splitVote  majVotes  minVotes  \n",
       "0           78.0             78.0          1         8         1  \n",
       "1           81.0             87.0          1         6         3  \n",
       "2           84.0             78.0          1         5         4  \n",
       "3           87.0             87.0          1         5         3  \n",
       "4           78.0             87.0          1         6         3  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/SCDB_2020_01_caseCentered_Citation.csv',encoding='cp1252' ) #importing data\n",
    "df.head() #checking the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering down to close votes and removing cases where who \n",
    "#the outcome was favorable for was unclear.\n",
    "df = df[df.majVotes < 7]\n",
    "df = df[df.partyWinning != 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Important Features Based on my EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data is almost all categorical data there are many Nans, they also decided to use floats for some reason. I'm going to extract my features then drop nans to preserve more rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going down to just the factors I want to use based on EDA and intuition\n",
    "#ie not including variable only known after the opinion is released etc...\n",
    "df = df[['lcDispositionDirection', 'issue', 'naturalCourt', 'jurisdiction', 'caseSource', 'petitioner','partyWinning']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping nans\n",
    "df.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3392 entries, 1 to 8662\n",
      "Data columns (total 7 columns):\n",
      "lcDispositionDirection    3392 non-null float64\n",
      "issue                     3392 non-null float64\n",
      "naturalCourt              3392 non-null int64\n",
      "jurisdiction              3392 non-null float64\n",
      "caseSource                3392 non-null float64\n",
      "petitioner                3392 non-null int64\n",
      "partyWinning              3392 non-null float64\n",
      "dtypes: float64(5), int64(2)\n",
      "memory usage: 212.0 KB\n"
     ]
    }
   ],
   "source": [
    "#checking for floats\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3392 entries, 1 to 8662\n",
      "Data columns (total 7 columns):\n",
      "lcDispositionDirection    3392 non-null int64\n",
      "issue                     3392 non-null int64\n",
      "naturalCourt              3392 non-null int64\n",
      "jurisdiction              3392 non-null int64\n",
      "caseSource                3392 non-null int64\n",
      "petitioner                3392 non-null int64\n",
      "partyWinning              3392 non-null int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 212.0 KB\n"
     ]
    }
   ],
   "source": [
    "#making sure it worked \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning my target to y and the predictive variables to y \n",
    "X = df.drop(['partyWinning'], axis = 1)\n",
    "Y = df['partyWinning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my baseline model, I will use a logistic regression with a simple penalty and a balanced class weight. I am not expecting too much, but it is an easy, interpretable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instancing a logistic regression model \n",
    "lgr = LogisticRegression(penalty = 'l2', class_weight= 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting \n",
    "lgr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preds = lgr.predict(X_test)\n",
    "baseline_preds_t = lgr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_test_accuracy = accuracy_score(baseline_preds, y_test)\n",
    "lgr_test_f1 = f1_score(baseline_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulating the Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Testing Accuracy: 0.4948\n",
      "\n",
      "F1 Score: 0.5457\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "print(\"Testing Accuracy: {:.4}\".format(lgr_test_accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(lgr_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 206\n",
      "True Negatives: 130\n",
      " False Positives: 119\n",
      " False Negatives: 224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, baseline_preds)#generating a confusion matrix\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "#printing it in the format which I find most readable, rather than the graphic version\n",
    "print( f'True Positives: {TP}\\n'\n",
    "       f'True Negatives: {TN}\\n', \n",
    "      f'False Positives: {FP}\\n',\n",
    "      f'False Negatives: {FN}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulating the Training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_train_accuracy = accuracy_score(baseline_preds_t, y_train)\n",
    "lgr_train_f1 = f1_score(baseline_preds_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Testing Accuracy: 0.5076\n",
      "\n",
      "F1 Score: 0.5371\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "print(\"Training Accuracy: {:.4}\".format(lgr_train_accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(lgr_train_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 775\n",
      "True Negatives: 602\n",
      " False Positives: 525\n",
      " False Negatives: 811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_train, baseline_preds_t)#generating a confusion matrix\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "#printing it in the format which I find most readable, rather than the graphic version\n",
    "print( f'True Positives: {TP}\\n'\n",
    "       f'True Negatives: {TN}\\n', \n",
    "      f'False Positives: {FP}\\n',\n",
    "      f'False Negatives: {FN}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model does not have great accuracy, but this is not that surprising for a base line logistic regression. It's also not overfit at all, as it performs equally poorly on the test and the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Relative Feature Importance')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = lgr.coef_[0]\n",
    "#feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "featfig = plt.figure()\n",
    "featax = featfig.add_subplot(1, 1, 1)\n",
    "featax.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "featax.set_yticks(pos)\n",
    "featax.set_yticklabels(np.array(X.columns)[sorted_idx], fontsize=8)\n",
    "featax.set_xlabel('Relative Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest Classifier is a good for categorization models and will naturally address the mild class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the model\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=0, class_weight= 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "rfc_preds = rfc.predict(X_test)\n",
    "rfc_preds_t = rfc.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulating the Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_test_accuracy = accuracy_score(rfc_preds, y_test)\n",
    "rfc_test_f1 = f1_score(rfc_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuned Random Forest Classifier\n",
      "Testing Accuracy: 0.6082\n",
      "\n",
      "F1 Score: 0.7011\n"
     ]
    }
   ],
   "source": [
    "print('Untuned Random Forest Classifier')\n",
    "print(\"Testing Accuracy: {:.4}\".format(rfc_test_accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(rfc_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 312\n",
      "True Negatives: 101\n",
      " False Positives: 148\n",
      " False Negatives: 118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, rfc_preds)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "print( f'True Positives: {TP}\\n'\n",
    "       f'True Negatives: {TN}\\n', \n",
    "      f'False Positives: {FP}\\n',\n",
    "      f'False Negatives: {FN}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaualting the Training Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train_accuracy = accuracy_score(rfc_preds_t, y_train)\n",
    "rfc_test_f1 = f1_score(rfc_preds_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuned Random Forest Classifier\n",
      "Training Accuracy: 0.9849\n",
      "\n",
      "F1 Score: 0.7011\n"
     ]
    }
   ],
   "source": [
    "print('Untuned Random Forest Classifier')\n",
    "print(\"Training Accuracy: {:.4}\".format(rfc_train_accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(rfc_train_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 1560\n",
      "True Negatives: 1112\n",
      " False Positives: 15\n",
      " False Negatives: 26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_train, rfc_preds_t)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "print( f'True Positives: {TP}\\n'\n",
    "       f'True Negatives: {TN}\\n', \n",
    "      f'False Positives: {FP}\\n',\n",
    "      f'False Negatives: {FN}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While more accutate then the logistic regression, this model is extremely overfit to the training data. Lets do a cross validated gridsearch to see if we can reduce the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV#importing the gridsearch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': range(9,15),\n",
    "    'max_features': ['auto']\n",
    "}#the hyper parameters I will test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanting the search\n",
    "grid_tree = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': range(9, 15),\n",
       "                         'max_features': ['auto'],\n",
       "                         'n_estimators': [100, 150, 200, 250]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting\n",
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions\n",
    "grfc_preds = grid_tree.predict(X_test)\n",
    "grfc_preds_t = grid_tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulating the Testing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "grfc_test_accuracy = accuracy_score(grfc_preds, y_test)\n",
    "grfc_test_f1 = f1_score(grfc_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuned Random Forest Classifier\n",
      "Testing Accuracy: 0.6318\n",
      "\n",
      "F1 Score: 0.7329\n"
     ]
    }
   ],
   "source": [
    "print('Untuned Random Forest Classifier')\n",
    "print(\"Testing Accuracy: {:.4}\".format(grfc_test_accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(grfc_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 343\n",
      "True Negatives: 86\n",
      " False Positives: 163\n",
      " False Negatives: 87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, grfc_preds)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "print( f'True Positives: {TP}\\n'\n",
    "       f'True Negatives: {TN}\\n', \n",
    "      f'False Positives: {FP}\\n',\n",
    "      f'False Negatives: {FN}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulating the Training Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "grfc_train_accuracy = accuracy_score(grfc_preds_t, y_train)\n",
    "grfc_train_f1 = f1_score(grfc_preds_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untuned Random Forest Classifier\n",
      "Testing Accuracy: 0.8087\n",
      "\n",
      "F1 Score: 0.7329\n"
     ]
    }
   ],
   "source": [
    "print('Untuned Random Forest Classifier')\n",
    "print(\"Testing Accuracy: {:.4}\".format(grfc_train_accuracy))\n",
    "print()\n",
    "print(\"F1 Score: {:.4}\".format(grfc_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 1510\n",
      "True Negatives: 684\n",
      " False Positives: 443\n",
      " False Negatives: 76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_train, grfc_preds_t)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "print( f'True Positives: {TP}\\n'\n",
    "       f'True Negatives: {TN}\\n', \n",
    "      f'False Positives: {FP}\\n',\n",
    "      f'False Negatives: {FN}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is slightly more accurate and has a higher f1 score, but worringly, is also fairly overfit to the trainin data. Lets check the best hyper parameters and see if they are at the extremes of our ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 9,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max depth is at the bottom of our range, lets run it again with lower possibiliies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': range(1,10),\n",
    "    'max_features': ['auto']\n",
    "}#the hyper parameters I will test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanting the search\n",
    "grid_tree = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   44.1s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': range(1, 10),\n",
       "                         'max_features': ['auto'],\n",
       "                         'n_estimators': [100, 150, 200, 250]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 9,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a max depth of nine was already a sweet spot, so this overfit model is the best we can do with only tuning our hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "332.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
